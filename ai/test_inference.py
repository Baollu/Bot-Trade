"""
Nexus Trade - ONNX Inference Test
Teste l'inf√©rence du mod√®le ONNX pour v√©rifier la latence (<100ms requis)
"""

import onnxruntime as ort
import numpy as np
import json
import time
from redis import Redis
import ta
import pandas as pd


class ONNXPredictor:
    """
    Pr√©dicteur utilisant le mod√®le ONNX export√©
    Optimis√© pour des inf√©rences ultra-rapides
    """
    
    def __init__(self, model_path='crypto_predictor.onnx', metadata_path='model_metadata.json'):
        """
        Charge le mod√®le ONNX et ses m√©tadonn√©es
        """
        print("üîÑ Chargement du mod√®le ONNX...")
        
        # Chargement du mod√®le ONNX
        self.session = ort.InferenceSession(
            model_path,
            providers=['CPUExecutionProvider']
        )
        
        # Chargement des m√©tadonn√©es
        with open(metadata_path, 'r') as f:
            self.metadata = json.load(f)
        
        self.sequence_length = self.metadata['sequence_length']
        self.features = self.metadata['features']
        self.scaler_mean = np.array(self.metadata['scaler_mean'])
        self.scaler_scale = np.array(self.metadata['scaler_scale'])
        self.classes = self.metadata['classes']
        
        print(f"‚úÖ Mod√®le charg√©: {self.metadata['model_type']} v{self.metadata['version']}")
        print(f"   S√©quence: {self.sequence_length} minutes")
        print(f"   Features: {len(self.features)}")
        print(f"   Classes: {self.classes}")
    
    def extract_features(self, df):
        """
        Extrait les features d'un DataFrame de prix
        """
        close = df['close']
        high = df['high']
        low = df['low']
        volume = df['volume']
        
        features_dict = {}
        
        # Price features
        features_dict['close'] = close.iloc[-1]
        features_dict['returns'] = close.pct_change().iloc[-1] if len(close) > 1 else 0.0
        features_dict['log_returns'] = np.log(close.iloc[-1] / close.iloc[-2]) if len(close) > 1 else 0.0
        
        # Volatility
        features_dict['volatility'] = close.rolling(window=min(20, len(close))).std().iloc[-1]
        features_dict['close_off_high'] = ((high.iloc[-1] - close.iloc[-1]) / high.iloc[-1]) if high.iloc[-1] != 0 else 0.0
        
        # RSI
        features_dict['rsi_14'] = ta.momentum.RSIIndicator(close, window=14).rsi().iloc[-1] if len(close) >= 14 else 50.0
        features_dict['rsi_7'] = ta.momentum.RSIIndicator(close, window=7).rsi().iloc[-1] if len(close) >= 7 else 50.0
        
        # MACD
        if len(close) >= 26:
            macd = ta.trend.MACD(close)
            features_dict['macd'] = macd.macd().iloc[-1]
            features_dict['macd_signal'] = macd.macd_signal().iloc[-1]
            features_dict['macd_diff'] = macd.macd_diff().iloc[-1]
        else:
            features_dict['macd'] = features_dict['macd_signal'] = features_dict['macd_diff'] = 0.0
        
        # Bollinger Bands
        if len(close) >= 20:
            bollinger = ta.volatility.BollingerBands(close)
            bb_high = bollinger.bollinger_hband().iloc[-1]
            bb_low = bollinger.bollinger_lband().iloc[-1]
            bb_mid = bollinger.bollinger_mavg().iloc[-1]
            features_dict['bb_high'] = bb_high
            features_dict['bb_low'] = bb_low
            features_dict['bb_mid'] = bb_mid
            features_dict['bb_width'] = (bb_high - bb_low) / bb_mid if bb_mid != 0 else 0
        else:
            features_dict['bb_high'] = features_dict['bb_low'] = features_dict['bb_mid'] = close.iloc[-1]
            features_dict['bb_width'] = 0.0
        
        # ATR
        features_dict['atr'] = ta.volatility.AverageTrueRange(high, low, close).average_true_range().iloc[-1] if len(close) >= 14 else 0.0
        
        # Moving Averages
        features_dict['sma_20'] = ta.trend.SMAIndicator(close, window=20).sma_indicator().iloc[-1] if len(close) >= 20 else close.iloc[-1]
        features_dict['ema_12'] = ta.trend.EMAIndicator(close, window=12).ema_indicator().iloc[-1] if len(close) >= 12 else close.iloc[-1]
        features_dict['ema_26'] = ta.trend.EMAIndicator(close, window=26).ema_indicator().iloc[-1] if len(close) >= 26 else close.iloc[-1]
        
        # Momentum
        if len(close) >= 10:
            features_dict['momentum_10'] = close.iloc[-1] - close.iloc[-11]
            features_dict['rate_of_change'] = ta.momentum.ROCIndicator(close).roc().iloc[-1]
        else:
            features_dict['momentum_10'] = features_dict['rate_of_change'] = 0.0
        
        # Volume
        features_dict['volume'] = volume.iloc[-1]
        volume_sma = volume.rolling(window=min(20, len(volume))).mean().iloc[-1]
        features_dict['volume_sma'] = volume_sma
        features_dict['volume_ratio'] = volume.iloc[-1] / volume_sma if volume_sma != 0 else 1.0
        
        # Stochastic
        if len(close) >= 14:
            stoch = ta.momentum.StochasticOscillator(high, low, close)
            features_dict['stoch_k'] = stoch.stoch().iloc[-1]
            features_dict['stoch_d'] = stoch.stoch_signal().iloc[-1]
        else:
            features_dict['stoch_k'] = features_dict['stoch_d'] = 50.0
        
        # OBV
        features_dict['obv'] = ta.volume.OnBalanceVolumeIndicator(close, volume).on_balance_volume().iloc[-1]
        
        # Retourne dans l'ordre des features du mod√®le
        return np.array([features_dict.get(feat, 0.0) for feat in self.features])
    
    def predict(self, prices_data):
        """
        Fait une pr√©diction √† partir des donn√©es de prix r√©centes
        
        Args:
            prices_data: Liste de dicts avec {open, high, low, close, volume}
        
        Returns:
            dict avec {class, probabilities, confidence, latency}
        """
        start_time = time.time()
        
        # Conversion en DataFrame
        df = pd.DataFrame(prices_data)
        
        # Extraction des features pour chaque point de temps
        features_sequence = []
        for i in range(len(df) - self.sequence_length + 1, len(df) + 1):
            df_slice = df.iloc[:i]
            features_sequence.append(self.extract_features(df_slice))
        
        # Normalisation
        features_array = np.array(features_sequence)
        features_normalized = (features_array - self.scaler_mean) / self.scaler_scale
        
        # Reshape pour ONNX: (1, sequence_length, num_features)
        input_data = features_normalized.reshape(1, self.sequence_length, -1).astype(np.float32)
        
        # Inf√©rence
        input_name = self.session.get_inputs()[0].name
        output_name = self.session.get_outputs()[0].name
        
        predictions = self.session.run([output_name], {input_name: input_data})[0]
        
        # R√©sultats
        predicted_class = int(np.argmax(predictions[0]))
        probabilities = predictions[0].tolist()
        confidence = float(max(probabilities))
        
        latency = (time.time() - start_time) * 1000  # en ms
        
        return {
            'class': self.classes[predicted_class],
            'class_id': predicted_class,
            'probabilities': {
                'NEUTRAL': probabilities[0],
                'UP': probabilities[1],
                'DOWN': probabilities[2]
            },
            'confidence': confidence,
            'latency_ms': latency
        }


def test_with_redis():
    """
    Test d'inf√©rence en r√©cup√©rant les donn√©es depuis Redis
    """
    print("\n" + "="*60)
    print("üß™ TEST D'INF√âRENCE AVEC REDIS")
    print("="*60)
    
    # Connexion √† Redis
    redis_client = Redis(host='localhost', port=6379, decode_responses=True)
    
    # Chargement du mod√®le
    predictor = ONNXPredictor()
    
    print("\nüìä R√©cup√©ration des donn√©es depuis Redis...")
    
    # R√©cup√©ration des derniers prix
    prices = redis_client.lrange('market_data:btcusdt', -predictor.sequence_length, -1)
    
    if len(prices) < predictor.sequence_length:
        print(f"‚ùå Pas assez de donn√©es: {len(prices)}/{predictor.sequence_length}")
        return
    
    # Conversion en format attendu
    prices_data = []
    for p in prices:
        price = float(p)
        prices_data.append({
            'open': price,
            'high': price * 1.001,
            'low': price * 0.999,
            'close': price,
            'volume': 1000.0
        })
    
    # Pr√©diction
    result = predictor.predict(prices_data)
    
    print("\n" + "="*60)
    print("üìà R√âSULTAT DE PR√âDICTION")
    print("="*60)
    print(f"Classe pr√©dite: {result['class']}")
    print(f"Confiance: {result['confidence']:.2%}")
    print(f"\nProbabilit√©s:")
    for cls, prob in result['probabilities'].items():
        print(f"  {cls:8s}: {prob:.2%}")
    print(f"\n‚è±Ô∏è  Latence: {result['latency_ms']:.2f} ms")
    
    if result['latency_ms'] < 100:
        print("‚úÖ Latence < 100ms: OBJECTIF ATTEINT!")
    else:
        print("‚ö†Ô∏è Latence > 100ms: OPTIMISATION REQUISE")
    
    print("="*60)


def test_with_synthetic_data():
    """
    Test d'inf√©rence avec des donn√©es synth√©tiques
    """
    print("\n" + "="*60)
    print("üß™ TEST D'INF√âRENCE AVEC DONN√âES SYNTH√âTIQUES")
    print("="*60)
    
    predictor = ONNXPredictor()
    
    # G√©n√©ration de donn√©es synth√©tiques
    base_price = 50000.0
    prices_data = []
    
    for i in range(predictor.sequence_length):
        price = base_price + np.random.randn() * 100
        prices_data.append({
            'open': price,
            'high': price + abs(np.random.randn() * 50),
            'low': price - abs(np.random.randn() * 50),
            'close': price,
            'volume': 1000 + abs(np.random.randn() * 500)
        })
    
    # Test de plusieurs pr√©dictions pour mesurer la latence moyenne
    latencies = []
    for _ in range(10):
        result = predictor.predict(prices_data)
        latencies.append(result['latency_ms'])
    
    print(f"\nüìä Statistiques de latence (10 pr√©dictions):")
    print(f"  Moyenne: {np.mean(latencies):.2f} ms")
    print(f"  Min:     {np.min(latencies):.2f} ms")
    print(f"  Max:     {np.max(latencies):.2f} ms")
    print(f"  Std:     {np.std(latencies):.2f} ms")
    
    if np.mean(latencies) < 100:
        print("\n‚úÖ Latence moyenne < 100ms: OBJECTIF ATTEINT!")
    else:
        print("\n‚ö†Ô∏è Latence moyenne > 100ms: OPTIMISATION REQUISE")


if __name__ == '__main__':
    # Test avec donn√©es synth√©tiques
    test_with_synthetic_data()
    
    # Test avec Redis (n√©cessite que Redis soit en cours d'ex√©cution)
    try:
        test_with_redis()
    except Exception as e:
        print(f"\n‚ö†Ô∏è Impossible de se connecter √† Redis: {e}")
        print("   Assurez-vous que Redis est d√©marr√© et contient des donn√©es")
